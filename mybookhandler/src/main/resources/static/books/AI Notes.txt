Fully observable if what your agent can sense at any time is completely sufficient to make<br>the optimal decision. <br><br>Partially observable where you need memory on the side of the agent to make the best possible<br>decision.&nbsp; &nbsp;THIRD EDIT TEST In deterministic models, the output of the model is fully determined <br>by the parameter values and the initial conditions initial conditions. <br><br>Stochastic models possess some inherent randomness. <br>The same set of parameter values and initial conditions will lead to an <br>ensemble of different outputs.<br><br>Discrete represents a finite number of values or moves. <br><br>Continuous represents an environment where the possibility may be infinite. <br><br>Benign environments the environment might be random, e.g. is weather<br><br>Adversarial, the environment is out to get you. e.g. chess you are trying to win<br><br>Definition of a problem<br>&gt;Initial State<br>&gt;Actions(S) -&gt; { a1, a2, a3 ....}<br> state as input and returns a set of possible of actions it can execute when it is<br> in this state<br>&gt;Result, a function that takes as input a state and action and delivers as its<br> output a new state<br>&gt;GoalTest, a function that takes a state and returns a boolean telling us if this<br> state is a goal or not<br>&gt;Path cost function, takes a path, a sequence of state action transitions and returns<br> a number which is a cost of that path. <br> StepCost(S, A, RESULTINGSTATE) returns N which is cost of that action e.g no. mins<br><br>The frontier are the furthest out states we can explore.<br><br>Tree Search Function Example<br><br>function tree.search(problem):<br>  frontier = {[initial]}<br>  loop:<br>    if frontier isempty: return FAIL<br>    path = remove.choice(frontier)<br>    s = path.end<br>    if s is a goal : return path<br>    for a in actions:<br>        add [path + a -&gt; Result(s,a)]<br>        to frontier<br><br>Different path finding algorithms<br>-BREADTH-FIRST SEARCH opposite is DEPTH FIRST SEARCH<br>-GRAPH SEARCH cheapest FIRST SEARCH<br>-UNIFORM-COST SEARCH - Guaranteed to find path with cheapest cost search<br><br>DEPTH FIRST SEARCH IS NOT AN OPTIMAL SEARCH PATTERN<br>However, one may one to use this algorithm for saving space, for example<br>	0<br>    0	    0<br>Consider these nodes. In depth first search, we run to the 'depth' first we will<br>have N nodes compared to 2n nodes for Breadth first<br>With depth first search we will never find an infinite tree goal if we assume that<br>it is following a path other than that which the goal is on. Say for example<br>in our tree above if it is infinte, and our goal is on the left. If we start with the <br>right, depth first search will never find it on the left as it will just keep going. <br><br>A* search<br>How far do we have to go?<br>Always expanding the path with has the min value of f<br>f= g + h<br>g(path) + path cost so far<br>h(path) = h(s) = estimated distance to goal<br><br>We want to minimise g and h. <br>*best estimated total path cost first*<br><br>A* will find the shortest path if h(s) &lt; true cost<br><br>Dijkstra Algorithm<br>Follows the shortest paths doesnt pay any direction. <br><br>State Space<br>Set of all possible states for a given problem <br><br>A* Search<br><br><br><br><br>